
<!DOCTYPE html>
<html lang="en-UK">
<head>
<meta charset="UTF-8" />
<meta name="author" content="Calum Ross" />
<meta name="generator" content="LaTeX Lwarp package" />
<meta name="description" content="Lecture notes for the module MAT1001 Differential Calculus." />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>MAT1001 Differential Calculus: Lecture Notes — Calculus in Computer Science</title>
<link rel="stylesheet" type="text/css" href="lwarp_sagebrush.css" />

<script>
// Lwarp MathJax emulation code
//
// Based on code by Davide P. Cervone.
// Equation numbering: https://github.com/mathjax/MathJax/issues/2427
// Starred and ifnextchar macros: https://github.com/mathjax/MathJax/issues/2428
// \left, \right delimiters: https://github.com/mathjax/MathJax/issues/2535
//
// Modified by Brian Dunn to adjust equation numbering and add subequations.
//
// LaTeX can use \seteqnumber{subequations?}{section}{number} before each equation.
// subequations? is 0 usually, 1 if inside subequations.
// section is a string printed as-is, or empty.
// number is auto-incremented by MathJax between equations.
//
MathJax = {
  subequations: "0",
  section: "",
  loader: {
    load: ['[tex]/tagformat', '[tex]/textmacros'],
  },
  startup: {
    ready() {
      // These would be replaced by import commands if you wanted to make
      // a proper extension.
      const Configuration = MathJax._.input.tex.Configuration.Configuration;
      const CommandMap = MathJax._.input.tex.SymbolMap.CommandMap;
      const Macro = MathJax._.input.tex.Symbol.Macro;
      const TexError = MathJax._.input.tex.TexError.default;
      const ParseUtil = MathJax._.input.tex.ParseUtil.default;
      const expandable = MathJax._.util.Options.expandable;

        // Insert the replacement string into the TeX string, and check
        // that there haven't been too many maxro substitutions (prevents
        // infinite loops).
        const useArgument = (parser, text) => {
          parser.string = ParseUtil.addArgs(parser, text, parser.string.slice(parser.i));
          parser.i = 0;
          if (++parser.macroCount > parser.configuration.options.maxMacros) {
            throw new TexError('MaxMacroSub1',
            'MathJax maximum macro substitution count exceeded; ' +
            'is there a recursive macro call?');
          }
        }

        // Create the command map for:
        //    \ifstar, \ifnextchar, \ifblank, \ifstrequal, \gsub, \seteqnumber
        new CommandMap('Lwarp-macros', {
          ifstar: 'IfstarFunction',
          ifnextchar: 'IfnextcharFunction',
          ifblank: 'IfblankFunction',
          ifstrequal: 'IfstrequalFunction',
          gsubstitute: 'GsubstituteFunction',
          seteqnumber: 'SeteqnumberFunction'
        }, {
          // This function implements an ifstar macro.
          IfstarFunction(parser, name) {
            const resultstar = parser.GetArgument(name);
            const resultnostar = parser.GetArgument(name);
            const star = parser.GetStar();                 // true if there is a *
            useArgument(parser, star ? resultstar : resultnostar);
          },

          // This function implements an ifnextchar macro.
          IfnextcharFunction(parser, name) {
            let whichchar = parser.GetArgument(name);
            if (whichchar.match(/^(?:0x[0-9A-F]+|[0-9]+)$/i)) {
              // $ syntax highlighting
              whichchar = String.fromCodePoint(parseInt(whichchar));
            }
            const resultnextchar = parser.GetArgument(name);
            const resultnotnextchar = parser.GetArgument(name);
            const gotchar = (parser.GetNext() === whichchar);
            useArgument(parser, gotchar ? resultnextchar : resultnotnextchar);
          },

          // This function implements an ifblank macro.
          IfblankFunction(parser, name) {
            const blankarg = parser.GetArgument(name);
            const resultblank = parser.GetArgument(name);
            const resultnotblank = parser.GetArgument(name);
            const isblank = (blankarg.trim() == "");
            useArgument(parser, isblank ? resultblank : resultnotblank);
          },

          // This function implements an ifstrequal macro.
          IfstrequalFunction(parser, name) {
            const strequalfirst = parser.GetArgument(name);
            const strequalsecond = parser.GetArgument(name);
            const resultequal = parser.GetArgument(name);
            const resultnotequal = parser.GetArgument(name);
            const isequal = (strequalfirst == strequalsecond);
            useArgument(parser, isequal ? resultequal : resultnotequal);
          },

          // This function implements a gsub macro.
          GsubstituteFunction(parser, name) {
            const gsubfirst = parser.GetArgument(name);
            const gsubsecond = parser.GetArgument(name);
            const gsubthird = parser.GetArgument(name);
            let gsubresult=gsubfirst.replace(gsubsecond, gsubthird);
            useArgument(parser, gsubresult);
          },

          // This function modifies the equation numbers.
          SeteqnumberFunction(parser, name) {
              // Get the macro parameters
              const star = parser.GetStar();                  // true if there is a *
              const optBrackets = parser.GetBrackets(name);   // contents of optional brackets
              const newsubequations = parser.GetArgument(name); // the subequations argument
              const neweqsection = parser.GetArgument(name); // the eq section argument
              const neweqnumber = parser.GetArgument(name);   // the eq number argument
              MathJax.config.subequations=newsubequations ;   // a string with boolean meaning
              MathJax.config.section=neweqsection ;           // a string with numeric meaning
              parser.tags.counter = parser.tags.allCounter = neweqnumber ;
          }

        });

        // Create the Lwarp-macros package
        Configuration.create('Lwarp-macros', {
          handler: {macro: ['Lwarp-macros']}
        });

        MathJax.startup.defaultReady();

        // For forward references:
        MathJax.startup.input[0].preFilters.add(({math}) => {
          if (math.inputData.recompile){
              MathJax.config.subequations = math.inputData.recompile.subequations;
              MathJax.config.section = math.inputData.recompile.section;
          }
        });
        MathJax.startup.input[0].postFilters.add(({math}) => {
          if (math.inputData.recompile){
              math.inputData.recompile.subequations = MathJax.config.subequations;
              math.inputData.recompile.section = MathJax.config.section;
          }
        });

          // For \left, \right with unicode-math:
          const {DelimiterMap} = MathJax._.input.tex.SymbolMap;
          const {Symbol} = MathJax._.input.tex.Symbol;
          const {MapHandler} = MathJax._.input.tex.MapHandler;
          const delimiter = MapHandler.getMap('delimiter');
          delimiter.add('\\lBrack', new Symbol('\\lBrack', '\u27E6'));
          delimiter.add('\\rBrack', new Symbol('\\rBrack', '\u27E7'));
          delimiter.add('\\lAngle', new Symbol('\\lAngle', '\u27EA'));
          delimiter.add('\\rAngle', new Symbol('\\rAngle', '\u27EB'));
          delimiter.add('\\lbrbrak', new Symbol('\\lbrbrak', '\u2772'));
          delimiter.add('\\rbrbrak', new Symbol('\\rbrbrak', '\u2773'));
          delimiter.add('\\lbag', new Symbol('\\lbag', '\u27C5'));
          delimiter.add('\\rbag', new Symbol('\\rbag', '\u27C6'));
          delimiter.add('\\llparenthesis', new Symbol('\\llparenthesis', '\u2987'));
          delimiter.add('\\rrparenthesis', new Symbol('\\rrparenthesis', '\u2988'));
          delimiter.add('\\llangle', new Symbol('\\llangle', '\u2989'));
          delimiter.add('\\rrangle', new Symbol('\\rrangle', '\u298A'));
          delimiter.add('\\Lbrbrak', new Symbol('\\Lbrbrak', '\u27EC'));
          delimiter.add('\\Rbrbrak', new Symbol('\\Rbrbrak', '\u27ED'));
          delimiter.add('\\lBrace', new Symbol('\\lBrace', '\u2983'));
          delimiter.add('\\rBrace', new Symbol('\\rBrace', '\u2984'));
          delimiter.add('\\lParen', new Symbol('\\lParen', '\u2985'));
          delimiter.add('\\rParen', new Symbol('\\rParen', '\u2986'));
          delimiter.add('\\lbrackubar', new Symbol('\\lbrackubar', '\u298B'));
          delimiter.add('\\rbrackubar', new Symbol('\\rbrackubar', '\u298C'));
          delimiter.add('\\lbrackultick', new Symbol('\\lbrackultick', '\u298D'));
          delimiter.add('\\rbracklrtick', new Symbol('\\rbracklrtick', '\u298E'));
          delimiter.add('\\lbracklltick', new Symbol('\\lbracklltick', '\u298F'));
          delimiter.add('\\rbrackurtick', new Symbol('\\rbrackurtick', '\u2990'));
          delimiter.add('\\langledot', new Symbol('\\langledot', '\u2991'));
          delimiter.add('\\rangledot', new Symbol('\\rangledot', '\u2992'));
          delimiter.add('\\lparenless', new Symbol('\\lparenless', '\u2993'));
          delimiter.add('\\rparengtr', new Symbol('\\rparengtr', '\u2994'));
          delimiter.add('\\Lparengtr', new Symbol('\\Lparengtr', '\u2995'));
          delimiter.add('\\Rparenless', new Symbol('\\Rparenless', '\u2996'));
          delimiter.add('\\lblkbrbrak', new Symbol('\\lblkbrbrak', '\u2997'));
          delimiter.add('\\rblkbrbrak', new Symbol('\\rblkbrbrak', '\u2998'));
          delimiter.add('\\lvzigzag', new Symbol('\\lvzigzag', '\u29D8'));
          delimiter.add('\\rvzigzag', new Symbol('\\rvzigzag', '\u29D9'));
          delimiter.add('\\Lvzigzag', new Symbol('\\Lvzigzag', '\u29DA'));
          delimiter.add('\\Rvzigzag', new Symbol('\\Rvzigzag', '\u29DB'));
          delimiter.add('\\lcurvyangle', new Symbol('\\lcurvyangle', '\u29FC'));
          delimiter.add('\\rcurvyangle', new Symbol('\\rcurvyangle', '\u29FD'));
          delimiter.add('\\Vvert', new Symbol('\\Vvert', '\u2980'));
    }     // ready
  },      // startup

  tex: {
    packages: {'[+]': ['tagformat', 'Lwarp-macros', 'textmacros']},
    tags: "ams",
        tagformat: {
            number: function (n) {
                if(MathJax.config.subequations==0)
                    return(MathJax.config.section + n);
                else
                    return(MathJax.config.section + String.fromCharCode(96+n));
            },
        },
  }
}
</script>

<script
    id="MathJax-script"
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"
></script>

</head>
<body>


<a id="mat1001-autopage-323"></a>
<div class="pagegrid">


<nav class="topnavigation"><a href="index.html" class="linkhome" >
Home</a></nav>
<div class="sidetoccontainer">


<nav class="sidetoc">


<div class="sidetoctitle">

<p>
<span class="sidetocthetitle">MAT1001 Differential Calculus: Lecture Notes</span>
</p>

<p>
Contents
</p>
</div>


<div class="sidetoccontents">

<p>
<a href="index.html" class="linkhome" >
Home</a>
</p>

<p>
<a href="Why-Do-We-Need-Calculus.html#autosec-5" class="tocchapter" >
<span class="sectionnumber">1</span>&#x2003;Why Do We Need Calculus</a>
</p>


<p>
<a href="Why-Do-We-Need-Calculus.html#autosec-6" class="tocsection" >
<span class="sectionnumber">1.1</span>&#x2003;Course Overview</a>
</p>


<p>
<a href="Why-Do-We-Need-Calculus.html#autosec-7" class="tocsection" >
<span class="sectionnumber">1.2</span>&#x2003;Why Calculus</a>
</p>


<p>
<a href="Functions.html#autosec-17" class="tocchapter" >
<span class="sectionnumber">2</span>&#x2003;Functions</a>
</p>


<p>
<a href="Functions.html#autosec-18" class="tocsection" >
<span class="sectionnumber">2.1</span>&#x2003;What is a function</a>
</p>


<p>
<a href="Functions.html#autosec-38" class="tocsection" >
<span class="sectionnumber">2.2</span>&#x2003;Trigonometric functions</a>
</p>


<p>
<a href="Functions.html#autosec-54" class="tocsection" >
<span class="sectionnumber">2.3</span>&#x2003;Logarithms and Exponentials</a>
</p>


<p>
<a href="Functions.html#autosec-65" class="tocsection" >
<span class="sectionnumber">2.4</span>&#x2003;Hyperbolic functions</a>
</p>


<p>
<a href="Functions.html#autosec-70" class="tocsection" >
<span class="sectionnumber">2.5</span>&#x2003;Limits and asymptotics</a>
</p>


<p>
<a href="Functions.html#autosec-84" class="tocsection" >
<span class="sectionnumber">2.6</span>&#x2003;Continuity and differentiability</a>
</p>


<p>
<a href="Differentiation.html#autosec-101" class="tocchapter" >
<span class="sectionnumber">3</span>&#x2003;Differentiation</a>
</p>


<p>
<a href="Differentiation.html#autosec-102" class="tocsection" >
<span class="sectionnumber">3.1</span>&#x2003;Differentiation from first principles</a>
</p>


<p>
<a href="Differentiation.html#autosec-111" class="tocsection" >
<span class="sectionnumber">3.2</span>&#x2003;Differentiation techniques</a>
</p>


<p>
<a href="Differentiation.html#autosec-131" class="tocsection" >
<span class="sectionnumber">3.3</span>&#x2003;Multiple derivatives</a>
</p>


<p>
<a href="Differentiation.html#autosec-133" class="tocsection" >
<span class="sectionnumber">3.4</span>&#x2003;Applications of differentiation</a>
</p>


<p>
<a href="Integration.html#autosec-157" class="tocchapter" >
<span class="sectionnumber">4</span>&#x2003;Integration</a>
</p>


<p>
<a href="Integration.html#autosec-158" class="tocsection" >
<span class="sectionnumber">4.1</span>&#x2003;Integration and antiderivatives</a>
</p>


<p>
<a href="Integration.html#autosec-168" class="tocsection" >
<span class="sectionnumber">4.2</span>&#x2003;Techniques for integration</a>
</p>


<p>
<a href="Integration.html#autosec-177" class="tocsection" >
<span class="sectionnumber">4.3</span>&#x2003;Definite integrals</a>
</p>


<p>
<a href="Integration.html#autosec-202" class="tocsection" >
<span class="sectionnumber">4.4</span>&#x2003;Applications of integrals</a>
</p>


<p>
<a href="Differential-Equations.html#autosec-214" class="tocchapter" >
<span class="sectionnumber">5</span>&#x2003;Differential Equations</a>
</p>


<p>
<a href="Numerical-Methods.html#autosec-216" class="tocchapter" >
<span class="sectionnumber">6</span>&#x2003;Numerical Methods</a>
</p>


<p>
<a href="Numerical-Methods.html#autosec-217" class="tocsection" >
<span class="sectionnumber">6.1</span>&#x2003;Solving equations numerically</a>
</p>


<p>
<a href="Numerical-Methods.html#autosec-249" class="tocsection" >
<span class="sectionnumber">6.2</span>&#x2003;Approximating functions</a>
</p>


<p>
<a href="Numerical-Methods.html#autosec-275" class="tocsection" >
<span class="sectionnumber">6.3</span>&#x2003;Numerical integration</a>
</p>


<p>
<a href="Numerical-Methods.html#autosec-301" class="tocsection" >
<span class="sectionnumber">6.4</span>&#x2003;Numerical differentiation</a>
</p>


<p>
<a href="Numerical-Methods.html#autosec-322" class="tocsection" >
<span class="sectionnumber">6.5</span>&#x2003;Numerical approaches to differential equations</a>
</p>


<p>
<a href="Calculus-in-Computer-Science.html#autosec-324" class="tocchapter" >
<span class="sectionnumber">7</span>&#x2003;Calculus in Computer Science</a>
</p>


<p>
<a href="Calculus-in-Computer-Science.html#autosec-325" class="tocsection" >
<span class="sectionnumber">7.1</span>&#x2003;LLMs and AI</a>
</p>


<p>
<a href="Calculus-in-Computer-Science.html#autosec-332" class="tocsection" >
<span class="sectionnumber">7.2</span>&#x2003;Robotics</a>
</p>


<p>
<a href="Advanced-Topics.html#autosec-334" class="tocchapter" >
<span class="sectionnumber">8</span>&#x2003;Advanced Topics</a>
</p>


<p>
<a href="Advanced-Topics.html#autosec-335" class="tocsection" >
<span class="sectionnumber">8.1</span>&#x2003;L’Ho&#x0302;pital’s rule for evaluating limits</a>
</p>


<p>
<a href="Advanced-Topics.html#autosec-339" class="tocsection" >
<span class="sectionnumber">8.2</span>&#x2003;Trigonometric Derivatives in Degrees</a>
</p>


<p>
<a href="Advanced-Topics.html#autosec-340" class="tocsection" >
<span class="sectionnumber">8.3</span>&#x2003;Functions of two variables</a>
</p>


<p>
<a href="Advanced-Topics.html#autosec-341" class="tocsection" >
<span class="sectionnumber">8.4</span>&#x2003;Multiple integrals</a>
</p>


<p>
<a href="Advanced-Topics.html#autosec-342" class="tocsection" >
<span class="sectionnumber">8.5</span>&#x2003;Optimisation Problems</a>
</p>


<p>
<a href="Advanced-Topics.html#autosec-345" class="tocsection" >
<span class="sectionnumber">8.6</span>&#x2003;Polynomial approximation</a>
</p>


<p>
<a href="Background-Mathematics.html#autosec-348" class="tocchapter" >
<span class="sectionnumber">9</span>&#x2003;Background Mathematics</a>
</p>


<p>
<a href="Background-Mathematics.html#autosec-349" class="tocsection" >
<span class="sectionnumber">9.1</span>&#x2003;Background and References</a>
</p>


<p>
<a href="Background-Mathematics.html#autosec-350" class="tocsection" >
<span class="sectionnumber">9.2</span>&#x2003;Polynomials and roots</a>
</p>


<p>
<a href="Background-Mathematics.html#autosec-352" class="tocsection" >
<span class="sectionnumber">9.3</span>&#x2003;Trigonometry Primer</a>
</p>


<p>
<a href="Background-Mathematics.html#autosec-356" class="tocsection" >
<span class="sectionnumber">9.4</span>&#x2003;Radians and Degrees</a>
</p>


<p>
<a href="Background-Mathematics.html#autosec-363" class="tocsection" >
<span class="sectionnumber">9.5</span>&#x2003;Rearranging Equations</a>
</p>


<p>
<a href="Background-Mathematics.html#autosec-368" class="tocsection" >
<span class="sectionnumber">9.6</span>&#x2003;More on Limits</a>
</p>


<p>
<a href="Further-Reading.html#autosec-371" class="tocchapter" >
<span class="sectionnumber">10</span>&#x2003;Further Reading</a>
</p>


<p>
<a href="Further-Reading.html#autosec-372" class="tocsection" >
<span class="sectionnumber">10.1</span>&#x2003;Why Calculus Extra Reading</a>
</p>


<p>
<a href="Further-Reading.html#autosec-373" class="tocsection" >
<span class="sectionnumber">10.2</span>&#x2003;Functions Extra Reading</a>
</p>


<p>
<a href="Further-Reading.html#autosec-374" class="tocsection" >
<span class="sectionnumber">10.3</span>&#x2003;Differentiation Extra Reading</a>
</p>


<p>
<a href="Further-Reading.html#autosec-375" class="tocsection" >
<span class="sectionnumber">10.4</span>&#x2003;Integration Extra Reading</a>
</p>


<p>
<a href="Further-Reading.html#autosec-376" class="tocsection" >
<span class="sectionnumber">10.5</span>&#x2003;Differential Equations Extra Reading</a>
</p>


<p>
<a href="Further-Reading.html#autosec-377" class="tocsection" >
<span class="sectionnumber">10.6</span>&#x2003;Numerical Methods Extra Reading</a>
</p>


<p>
<a href="Further-Reading.html#autosec-378" class="tocsection" >
<span class="sectionnumber">10.7</span>&#x2003;Calculus in Computer Science</a>
</p>


<p>
<a href="Further-Reading.html#autosec-379" class="tocsection" >
<span class="sectionnumber">10.8</span>&#x2003;Advanced Topics Extra Reading</a>
</p>


<p>
<a href="Tutorial-Sheets.html#autosec-381" class="tocchapter" >
<span class="sectionnumber">11</span>&#x2003;Tutorial Sheets</a>
</p>


<p>
<a href="Tutorial-Sheets.html#autosec-382" class="tocsection" >
<span class="sectionnumber">11.1</span>&#x2003;Week 1</a>
</p>


<p>
<a href="Tutorial-Sheets.html#autosec-398" class="tocsection" >
<span class="sectionnumber">11.2</span>&#x2003;Week 2</a>
</p>


<p>
<a href="Tutorial-Sheets.html#autosec-422" class="tocsection" >
<span class="sectionnumber">11.3</span>&#x2003;Week 3</a>
</p>


<p>
<a href="Tutorial-Sheets.html#autosec-440" class="tocsection" >
<span class="sectionnumber">11.4</span>&#x2003;Week 4</a>
</p>


<p>
<a href="Tutorial-Sheets.html#autosec-448" class="tocsection" >
<span class="sectionnumber">11.5</span>&#x2003;Week 5</a>
</p>


<p>
<a href="Tutorial-Sheets.html#autosec-471" class="tocsection" >
<span class="sectionnumber">11.6</span>&#x2003;Week 8</a>
</p>


<p>
<a href="Tutorial-Sheets.html#autosec-481" class="tocsection" >
<span class="sectionnumber">11.7</span>&#x2003;Week 9</a>
</p>


<p>
<a href="Tutorial-Sheets.html#autosec-493" class="tocsection" >
<span class="sectionnumber">11.8</span>&#x2003;Week 10</a>
</p>


<p>
<a href="Extra-Proofs-Derivations.html#autosec-504" class="tocchapter" >
<span class="sectionnumber">12</span>&#x2003;Extra Proofs and Derivations</a>
</p>


<p>
<a href="Standard-Derivatives-Integrals.html#autosec-507" class="tocchapter" >
<span class="sectionnumber">13</span>&#x2003;Standard Derivatives and Integrals</a>
</p>


<p>
<a href="Standard-Derivatives-Integrals.html#autosec-508" class="tocsection" >
<span class="sectionnumber">13.1</span>&#x2003;Derivatives</a>
</p>


<p>
<a href="Standard-Derivatives-Integrals.html#autosec-511" class="tocsection" >
<span class="sectionnumber">13.2</span>&#x2003;Integrals</a>
</p>


<p>
<a href="Bibliography.html#autosec-515" class="tocchapter" >
Bibliography</a>
</p>


</div>

</nav>

</div>


<main class="bodycontainer">


<section class="textbody">

<h1>MAT1001 Differential Calculus: Lecture Notes</h1>

<!--MathJax customizations:-->
<div data-nosnippet
    style="display:none"
>

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\let \LWRorighspace \hspace \)

\(\renewcommand {\hspace }{\ifstar \LWRorighspace \LWRorighspace }\)

\(\newcommand {\TextOrMath }[2]{#2}\)

\(\newcommand {\mathnormal }[1]{{#1}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\arabic }[1]{}\)

\(\newcommand {\number }[1]{}\)

\(\newcommand {\noalign }[1]{\text {#1}\notag \\}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\newcommand {\LWRabsorboption }[1][]{}\)

\(\newcommand {\LWRabsorbtwooptions }[1][]{\LWRabsorboption }\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\def \oe {\unicode {x0153}}\)

\(\def \OE {\unicode {x0152}}\)

\(\def \ae {\unicode {x00E6}}\)

\(\def \AE {\unicode {x00C6}}\)

\(\def \aa {\unicode {x00E5}}\)

\(\def \AA {\unicode {x00C5}}\)

\(\def \o {\unicode {x00F8}}\)

\(\def \O {\unicode {x00D8}}\)

\(\def \l {\unicode {x0142}}\)

\(\def \L {\unicode {x0141}}\)

\(\def \ss {\unicode {x00DF}}\)

\(\def \SS {\unicode {x1E9E}}\)

\(\def \dag {\unicode {x2020}}\)

\(\def \ddag {\unicode {x2021}}\)

\(\def \P {\unicode {x00B6}}\)

\(\def \copyright {\unicode {x00A9}}\)

\(\def \pounds {\unicode {x00A3}}\)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\require {textcomp}\)

\(\require {upgreek}\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\let \Hat \hat \)

\(\let \Check \check \)

\(\let \Tilde \tilde \)

\(\let \Acute \acute \)

\(\let \Grave \grave \)

\(\let \Dot \dot \)

\(\let \Ddot \ddot \)

\(\let \Breve \breve \)

\(\let \Bar \bar \)

\(\let \Vec \vec \)

\(\require {cancel}\)

\(\newcommand {\LWRsubmultirow }[2][]{#2}\)

\(\newcommand {\LWRmultirow }[2][]{\LWRsubmultirow }\)

\(\newcommand {\multirow }[2][]{\LWRmultirow }\)

\(\newcommand {\mrowcell }{}\)

\(\newcommand {\mcolrowcell }{}\)

\(\newcommand {\STneed }[1]{}\)

\(\def \ud {\mathrm {d}}\)

\(\def \ui {\mathrm {i}}\)

\(\def \uj {\mathrm {j}}\)

\(\def \uh {\mathrm {h}}\)

\(\newcommand {\R }{\mathbb {R}}\)

\(\newcommand {\N }{\mathbb {N}}\)

\(\newcommand {\C }{\mathbb {C}}\)

\(\newcommand {\Z }{\mathbb {Z}}\)

\(\newcommand {\CP }{\mathbb {C}P}\)

\(\newcommand {\RP }{\mathbb {R}P}\)

\(\def \bk {\vec {k}}\)

\(\def \bm {\vec {m}}\)

\(\def \bn {\vec {n}}\)

\(\def \be {\vec {e}}\)

\(\def \bE {\vec {E}}\)

\(\def \bx {\vec {x}}\)

\(\def \uL {\mathrm {L}}\)

\(\def \uU {\mathrm {U}}\)

\(\def \uW {\mathrm {W}}\)

\(\def \uE {\mathrm {E}}\)

\(\def \uT {\mathrm {T}}\)

\(\def \uV {\mathrm {V}}\)

\(\def \uM {\mathrm {M}}\)

\(\def \uH {\mathrm {H}}\)

\(\DeclareMathOperator {\sech }{sech}\)

\(\DeclareMathOperator {\csch }{csch}\)

\(\DeclareMathOperator {\arcsec }{arcsec}\)

\(\DeclareMathOperator {\arccot }{arcCot}\)

\(\DeclareMathOperator {\arccsc }{arcCsc}\)

\(\DeclareMathOperator {\arccosh }{arcCosh}\)

\(\DeclareMathOperator {\arcsinh }{arcsinh}\)

\(\DeclareMathOperator {\arctanh }{arctanh}\)

\(\DeclareMathOperator {\arcsech }{arcsech}\)

\(\DeclareMathOperator {\arccsch }{arcCsch}\)

\(\DeclareMathOperator {\arccoth }{arcCoth}\)

\(\def \re {\textup {Re}}\)

\(\def \im {\textup {Im}}\)

\(\newcommand {\up }{\uppi }\)

\(\newcommand {\ut }{\uptheta }\)

\(\newcommand {\uw }{\upomega }\)

\(\newcommand {\uph }{\upphi }\)

\(\newcommand {\uvph }{\upvarphi }\)

</div>

<!--
...... chapter Calculus in Computer Science ......
-->
<h3 id="autosec-324">Chapter&nbsp;<span class="sectionnumber">7&#x2003;</span>Calculus in Computer Science</h3>
<a id="mat1001-autopage-324"></a>
<a id="mat1001-autofile-7"></a>

<a id="sec:CS calc"></a>

<div class="epigraph" role="note">


<div class="qitem">

<p>
Machines take me by surprise with great frequency.
</p>

<div class="epigraphsource">

<p>
<i>Alan Turing</i>
</p>
</div>

</div>

</div>

<p>
In most of this module we have focussed on the mathematics, and even when trying to motivate the connection to computer science we have been fairly sketchy. In this chapter we are going to rectify that and discuss some concrete examples of where the material that you
have studied here is of relevance to Computer Science, AI, and Machine Learning.<br />

</p>

<p>
If you try to read this chapter before covering all of the basics you may find the examples hard to follow, but if you have finished everything up to chapter&nbsp;<a href="Integration.html#sec:integration">4</a>, then you should be fine.<br />

</p>

<p>
This chapter is split into sections, at least one of which should be relevant to each of the degree schemes that this module is included on, <b>Computer Science, Computer Science and AI, and Robotics and AI</b>. This does not mean that you will not find
examples of interest in other sections, it just means that I am trying to group the examples thematically. As with several other chapters, this is a work in progress and will be adapted and expanded over time. Be sure to check back frequently if you want to see the most up
to date examples.
</p>
<!--
...... section LLMs and AI ......
-->
<h4 id="autosec-325"><span class="sectionnumber">7.1&#x2003;</span>LLMs and AI</h4>
<a id="mat1001-autopage-325"></a>


<p>
Large language models (LLMs) are basically<sup>1</sup> big functions and compositions of functions. Think of it like fig.&nbsp;<a href="Calculus-in-Computer-Science.html#fig:   simple llm">7.1</a>, where we have input data \(x\) which the function sends to an
output \(f(x)\).<br />

</p>

<figure id="autoid-53" class="figure ">
<div class="center">

<p>
<span
    id="lateximage-mat1001-31"
    class="lateximagesource"
><!--
  x     f    f (x)
input       output
--><img
    src="mat1001-images\image-31.svg"
    alt="(A schematic of a LLM as a function.)"
    style=""
    class="lateximage"
></span>
</p>


<div class="figurecaption">
Figure&nbsp;7.1: A schematic of a LLM as a function where the parameters are tuned to take an input and return a specific output.

</div>

<a id="fig:   simple llm"></a>

</div>

</figure>

<p>
Here we focus on the simplest case where there is one input, one output, and the function \(f\) has a single parameter. In a real system this will be much more complicated, but then you need to be able to use calculus in several variables which is beyond this module. If
you are interested in knowing more about the general story let me know and I can provide some further resources.<br />

</p>

<p>
In this picture the function \(f\) is a model that tells us how the input is mapped to the output. The parameters in the model tell us how this happens.
</p>
<div role="note" class="footnotes">

<a id="mat1001-autopage-329"></a>

<p>
<sup>1</sup>&nbsp;This is a real simplification. 3Blue1Brown has a playlist on Neural Networks, available <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi" target="_blank" >here</a>, which explains more about the
applications of calculus to LLMs and what is really going on.
</p>


</div>



<div class="amsthmbodyplain">

<ul class="list" style="list-style-type:none">


<li>
<p>
<span class="listmarker">
<span class="amsthmnameplain">Example</span><span class="amsthmnumberplain"> <span class="textup">7.1</span></span>. </span> Consider the function which sends \(x\) to \(f(x)=ax +b\), this has two parameters \(a\) and \(b\).
</p>

</li>

</ul>

</div>

<p>
When training a model we use training data where we already know the true output \(y\) that we want to get from a given input \(x\). To do this we essentially want to find the “best” values of \(a\) and \(b\), or whatever the parameters are, so that our functions
output \(\hat {y}\) is as close as possible to the true value \(y\).<br />

</p>

<p>
If we are sticking to a simple one parameter model then given the input \(x\) we get out put \(\hat {y}(w)=f(w,x)\), where \(f(x)\) will be a function like \(f(w,x)=x+w, wx, e^{wx}, \sin (wx), \dots \). For the training data we then measure the difference between
\(\hat {y}(w)\) and the true output \(y\) for the fixed input \(x\).<br />

</p>

<p>
This difference between \(\hat (y)(w)\) and \(y\) is called an error term, it measures how far out our model is from the true answer. For example \(y-\hat {y}(w)\) is a linear error term, while \((y-\hat {y}(w))^{2}\) is a quadratic error term. If we treat the error
term as a function of the parameter \(w\) and find its critical points this will tell us the values of the parameter that minimise or maximise the error, and we want to minimise the error term.<br />

</p>

<p>
This error function is often called the <b>loss function</b>. Loss functions appear generally in decision theory and the study of optimisation problems. They appear whenever you are training an AI or LLM, where they measure the deviation of the model’s output
against the true value for the training data.<br />

</p>

<p>
A conventional choice of loss function is the quadratic loss function
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{0}\)</span>

<!--


                                                                                          λ(w) = (ŷ(w) − y)2                                                                                           (7.1)                   --><a id="eq:    quadratic loss"></a><!--

-->

<p>

\begin{equation}
\lambda (w)=\left (\hat {y}(w)-y\right )^{2} \label {eq:           quadratic loss}
\end{equation}

</p>

<p>
Again the idea that given a function \(f\) with a single free parameter \(w\) we want to minimise \(\lambda (w)\) for fixed input \(x\) and fixed true output \(y\). The optimisation method used is called <b>gradient flow</b>. In a one dimensional case we are solving
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{1}\)</span>

<!--

                                                                                                                                  dλ
                                                                                                                                     =0
                                                                                                                                  dw
-->

<p>

\begin{equation*}
\frac {\ud \lambda }{\ud w}=0
\end{equation*}

</p>

<p>
for \(w\), to get the optimal \(\hat {y}(w)\) for a given \(x\).
</p>
<div class="amsthmbodyplain">

<ul class="list" style="list-style-type:none">


<li>
<p>
<span class="listmarker"><a id="mat1001-autopage-330"></a>
<span class="amsthmnameplain">Real World Application</span><span class="amsthmnumberplain"> <span class="textup">7.1</span></span>. </span> Consider the one parameter model \(\hat {y}(w)=\sin (wx)\) and the quadratic loss function in eq.&nbsp;<span
class="textup">(<a href="Calculus-in-Computer-Science.html#eq:           quadratic loss">7.1</a>)</span>. If the input is \(x=\pi \) and the desired output is \(y=0\) then the loss function becomes
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{1}\)</span>

<!--


                                                                                                                     λ(w) = (sin(wπ) − 0)2 = (sin(wπ))2 .

-->

<p>


\begin{equation*}
\lambda (w)=\left (\sin (w\pi )-0\right )^{2}=\left (\sin (w\pi )\right )^{2}.
\end{equation*}


</p>

<p>
Then
</p>
<span class="hidden"> \(\seteqnumber{0}{7.}{1}\)</span>


<!--



                                                                                                                              dλ
                                                                                                                                 = 2π sin(wπ) cos(wπ)
                                                                                                                              dw
                                                                                                                                  = π sin(2wπ).



-->


<p>


\begin{align*}
\frac {\ud \lambda }{\ud w} &amp;=2\pi \sin (w\pi )\cos (w\pi )\\ &amp;=\pi \sin (2w\pi ).
\end{align*}
This is zero when \(w=\pm 1,\pm 2,\pm 3, \dots \) or \(w=\pm 1/2, \pm 3/2, \pm 5/2, \dots \). i.e. \(w\) is either an integer or a half-integer.
</p>

<p>
Looking at the second derivative we see that
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{1}\)</span>

<!--


                                                                                                                               d2 λ
                                                                                                                                    = 2π 2 cos(2wπ),
                                                                                                                               dw2

-->

<p>


\begin{equation*}
\frac {\ud ^{2} \lambda }{\ud w^{2}}=2\pi ^{2}\cos (2w\pi ),
\end{equation*}


</p>

<p>
and that
</p>
<span class="hidden"> \(\seteqnumber{0}{7.}{1}\)</span>


<!--



                                                                                                                                 d2 λ
                                                                                                                                      (±1, ±2, . . . ) > 0
                                                                                                                                 dw2
                                                                                                                               2
                                                                                                                              d λ
                                                                                                                                   
                                                                                                                                       1   3
                                                                                                                                                   
                                                                                                                                 2
                                                                                                                                     ± ,± ,... < 0
                                                                                                                              dw       2   2


-->


<p>


\begin{align*}
\frac {\ud ^{2} \lambda }{\ud w^{2}}\left (\pm 1,\pm 2, \dots \right )&amp;&gt;0\\ \frac {\ud ^{2} \lambda }{\ud w^{2}}\left (\pm \frac {1}{2},\pm \frac {3}{2}, \dots \right )&amp;&lt;0
\end{align*}
So integer values of \(w\) are minima and half integer values are maxima.<br />


</p>

<p>
For all of these values \(f:\pi \mapsto 0\) so you would need to look at more training data to fix a single value of \(w\).
</p>

</li>

</ul>

</div>

<p>
It is important to note that while optimisation can get the output closer to the true value, how close it can get depends on how good the choice of model \(f\) is.
</p>
<div class="amsthmbodyplain">

<ul class="list" style="list-style-type:none">


<li>
<p>
<span class="listmarker"><a id="mat1001-autopage-331"></a>
<span class="amsthmnameplain">Example</span><span class="amsthmnumberplain"> <span class="textup">7.2</span></span>. </span> Consider the model
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{1}\)</span>

<!--


                                                                                                                                                wx
                                                                                                                                  ŷ(w) =               ,
                                                                                                                                             1 + w 2 x2

-->

<p>


\begin{equation*}
\hat {y}(w)=\frac {wx}{1+w^{2}x^{2}},
\end{equation*}


</p>

<p>
alongside the quadratic loss function. If the target output for input \(x=1\) is \(y=2\) what is the optimal value of \(w\)?<br />


</p>

<p>
For \(x=1\) and \(y=2\) the loss function becomes
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{1}\)</span>

<!--

                                                                                                                                                          2
                                                                                                                                              w
                                                                                                                                        
                                                                                                                              ŷ(w) =              −2          .
                                                                                                                                            1 + w2

-->

<p>


\begin{equation*}
\hat {y}(w)=\left (\frac {w}{1+w^{2}}-2\right )^{2}.
\end{equation*}


</p>

<p>
Note here that \(w/(1+w^{2})&lt;1/2\) so we can never get \(\lambda (w)=0\), i.e. this model is a bad fit for the training data.<br />


</p>

<p>
If we optimise anyway then we get
</p>
<span class="hidden"> \(\seteqnumber{0}{7.}{1}\)</span>


<!--



                                                                                                                       dλ      w         d      w
                                                                                                                                                                
                                                                                                                          2        −2
                                                                                                                       dw   1 + w2     dw 1 + w2
                                                                                                                                 w          (1 − w2 )
                                                                                                                                       
                                                                                                                           =2       2
                                                                                                                                      −2              .
                                                                                                                                1+w        (1 + w2 )2


-->


<p>


\begin{align*}
\frac {\ud \lambda }{\ud w} &amp;2\left (\frac {w}{1+w^{2}}-2\right )\frac {\ud }{\ud w}\left (\frac {w}{1+w^{2}}\right )\\ &amp;=2\left (\frac {w}{1+w^{2}}-2\right )\frac {(1-w^{2})}{(1+w^{2})^{2}}.
\end{align*}
We know that the first bracket does not vanish so this is zero when \(1-w^{2}=0\) giving \(w=\pm 1\). If \(w=1\) then \(\lambda (+1)=9/4\) while \(\lambda (-1)=25/4\) so \(w=+1\) is the minimum. Bot for this choice of \(w\) the output is
</p>

<span class="hidden"> \(\seteqnumber{0}{7.}{1}\)</span>

<!--


                                                                                                                                          1   1
                                                                                                                               ŷ(1) =       = ̸= 2
                                                                                                                                         1+1  2

-->

<p>


\begin{equation*}
\hat {y}(1)=\frac {1}{1+1}=\frac {1}{2}\neq 2
\end{equation*}


</p>

<p>
So we do not get a match for the desired output.
</p>

</li>

</ul>

</div>

<p>
This example of optimisation not working is a useful warning as it shows us that while optimisation is a powerful and useful model you still need to start from a sensible model.
</p>
<!--
...... section Robotics ......
-->
<h4 id="autosec-332"><span class="sectionnumber">7.2&#x2003;</span>Robotics</h4>
<a id="mat1001-autopage-332"></a>


<p>
<span
    class="textcolor"
    style="color:#FF0000"
>To be added.</span>
</p>

</section>

</main>

<footer>

<p>
Contact <a href="mailto:rossc@edgehill.ac.uk" target="_blank" >rossc[at]edgehill[dot]ac[dot]uk</a> and Copyright CC BY 4.0
</p>

</footer>


<nav class="botnavigation"><a href="index.html" class="linkhome" >
Home</a></nav>

</div><!-- grid -->
</body>
</html>
